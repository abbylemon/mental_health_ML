{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cloud_setup.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNjyhZv6CY6VF2bhPc7eupB"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cHrIAxf0Mkot","colab_type":"text"},"source":["# AWS Cloud Setup\n","\n","Run through the following cells to set up a S3 bucket where the csv data files for this project will be stored."]},{"cell_type":"markdown","metadata":{"id":"z2WqPX6yMcKi","colab_type":"text"},"source":["## Set up Spark session\n"]},{"cell_type":"code","metadata":{"id":"JFbAZM5__K7b","colab_type":"code","colab":{}},"source":["# Install Java, Spark, and Findspark\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q8BYSr5z_eJ4","colab_type":"code","colab":{}},"source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"CloudSetup\").getOrCreate()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HvuSq7vmNYPZ","colab_type":"text"},"source":["## Mount Google Drive into this runtime\n","\n","To store the csv data files in an S3 bucket, you need to mount your google drive into this runtime. To do that, run the following cells.\n","\n","This will prompt a URL with an authentication code. After you go to the URL and insert that authentication code in the provided space, your google drive will be mounted."]},{"cell_type":"code","metadata":{"id":"9nnXhYiIBcNt","colab_type":"code","outputId":"7d9bfef2-f956-4c3d-806f-a961678a7ca1","executionInfo":{"status":"ok","timestamp":1589113774905,"user_tz":300,"elapsed":45176,"user":{"displayName":"Philip Stubbs","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs77NEPtyu7xu6gp5w4tMARedDDBncqvcfCfPIBw=s64","userId":"02797545812686497806"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WigClWggBomb","colab_type":"code","outputId":"0d9b423c-95d3-4fe5-bb3c-bd96cfeec3f9","executionInfo":{"status":"ok","timestamp":1589113788345,"user_tz":300,"elapsed":1450,"user":{"displayName":"Philip Stubbs","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs77NEPtyu7xu6gp5w4tMARedDDBncqvcfCfPIBw=s64","userId":"02797545812686497806"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Check the contents of the current folder in the runtime.\n","! ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["gdrive\tsample_data  spark-2.4.5-bin-hadoop2.7\tspark-2.4.5-bin-hadoop2.7.tgz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bXcyjFggB5sZ","colab_type":"code","outputId":"923cd30d-28a4-4047-a1c7-628994005676","executionInfo":{"status":"ok","timestamp":1589113796845,"user_tz":300,"elapsed":323,"user":{"displayName":"Philip Stubbs","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs77NEPtyu7xu6gp5w4tMARedDDBncqvcfCfPIBw=s64","userId":"02797545812686497806"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# If the drive is mounted correcly, you will see that the current folder has a directory called gdrive.\n","# This is where you can find your google drive contents. \n","%cd /content/gdrive/My Drive"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C6w3OXYWJOhu","colab_type":"code","outputId":"c977a3b0-6938-484a-f226-64082ca68439","executionInfo":{"status":"ok","timestamp":1589113808604,"user_tz":300,"elapsed":358,"user":{"displayName":"Philip Stubbs","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs77NEPtyu7xu6gp5w4tMARedDDBncqvcfCfPIBw=s64","userId":"02797545812686497806"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Create folder in Google Drive to temporarily store the csv data files.\n","project_folder_exists = os.path.isdir('data_final_project')\n","\n","# If the project folder doesnt exist, create it.\n","if project_folder_exists == False:\n","  %mkdir data_final_project/\n","\n","# Otherwise, change into that directory.\n","%cd data_final_project"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/data_final_project\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NKZyFgNDOX8X","colab_type":"text"},"source":["## Clone GitHub Repository\n","\n","Running this cell clones the repository into google drive (if the repository doesn't already exist in google drive). If the repository already exists in google drive, then running this cell will simply pull the latest changes from master.\n","\n","As part of this step, you will need to enter your github email and github username. So, have those ready.\n","\n","Running this cell sometimes takes a few minutes..."]},{"cell_type":"code","metadata":{"id":"2jD_c-1gDiyg","colab_type":"code","outputId":"207fef93-1569-4afc-ae5e-a9901854579e","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1589114259838,"user_tz":300,"elapsed":421589,"user":{"displayName":"Philip Stubbs","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs77NEPtyu7xu6gp5w4tMARedDDBncqvcfCfPIBw=s64","userId":"02797545812686497806"}}},"source":["repo_exists = os.path.isdir('mental_health_ML')\n","\n","email = input('GitHub Email: ')\n","username = input('GitHub Username: ')\n","\n","!git config --global user.email email\n","!git config --global user.name username\n","\n","if repo_exists == False:\n","  ! git clone https://github.com/abbylemon/mental_health_ML.git\n","\n","%cd mental_health_ML/\n","\n","! git add .\n","! git stash\n","! git pull origin master\n","! git stash pop"],"execution_count":7,"outputs":[{"output_type":"stream","text":["GitHub Email: philipstubbs13@gmail.com\n","GitHub Username: philipstubbs13\n","/content/gdrive/My Drive/data_final_project/mental_health_ML\n","Saved working directory and index state WIP on aws_cloud_setup: 2c5b85d start\n","From https://github.com/abbylemon/mental_health_ML\n"," * branch            master     -> FETCH_HEAD\n","Already up to date.\n","^C\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"04rcBUM5Plr_","colab_type":"text"},"source":["## Extract the csv data files from the zip file\n","\n","Running this cell will extract the csv data files from the .zip file inside the Resources folder of the repository."]},{"cell_type":"code","metadata":{"id":"UiPZMTaoEzxH","colab_type":"code","outputId":"908430eb-bbf5-45f5-9ae2-a4d19c07fe41","executionInfo":{"status":"ok","timestamp":1589114266781,"user_tz":300,"elapsed":430,"user":{"displayName":"Philip Stubbs","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs77NEPtyu7xu6gp5w4tMARedDDBncqvcfCfPIBw=s64","userId":"02797545812686497806"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["import zipfile\n","\n","# unzip files in Resources folder.\n","extension = \".zip\"\n","extracted_dir_name = \".\"\n","\n","# Get the current working directory.\n","# Need to be in root directory of repo for this to work.\n","cwd_dir_name = os.getcwd()\n","print(f\"The current working directory is {cwd_dir_name}.\")\n","\n","# change directory from working dir to dir with zip file.\n","os.chdir(\"Resources\")\n","# This should be the \"Resources\" folder.\n","dir_name = os.getcwd()\n","print(f\"You are now in the following directory: {dir_name}.\")\n","\n","# loop through the items in the directory.\n","for item in os.listdir(dir_name):\n","  # check for \".zip\" extension\"\n","  if item.endswith(extension):\n","    try:\n","      # get full path of files\n","      file_name = os.path.abspath(item)\n","      # create zipfile object\n","      zip_ref = zipfile.ZipFile(file_name)\n","      # reference to the directory where the zip files will be extracted.\n","      unzipped_directory = os.path.join(extracted_dir_name)\n","      # extract file to dir\n","      zip_ref.extractall(unzipped_directory)\n","      # close file\n","      zip_ref.close()\n","      print(f\"Successfully unzipped {item} into the following folder:{dir_name}.\")\n","    except Exception as e:\n","      print(f\"Error trying to unzip data file(s).\")\n","      print(e)\n","            \n","# Go up one directory into the repo root directory.\n","os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir))\n","print(os.path.normpath(os.getcwd() + os.sep + os.pardir))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["The current working directory is /content/gdrive/My Drive/data_final_project/mental_health_ML.\n","You are now in the following directory: /content/gdrive/My Drive/data_final_project/mental_health_ML/Resources.\n","Successfully unzipped osmi_mental_health_in_tech_survey_results.zip into the following folder:/content/gdrive/My Drive/data_final_project/mental_health_ML/Resources.\n","/content/gdrive/My Drive/data_final_project\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7_v8dYkLQiHE","colab_type":"text"},"source":["## Install Boto3\n","\n","Boto3 is the AWS SDK for Python to create, configure, and manage AWS Services, such as S3."]},{"cell_type":"code","metadata":{"id":"_uNJaV4CTYAH","colab_type":"code","outputId":"4121f887-28cd-4de5-be4c-f6d4c647e487","executionInfo":{"status":"ok","timestamp":1589114295793,"user_tz":300,"elapsed":3119,"user":{"displayName":"Philip Stubbs","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs77NEPtyu7xu6gp5w4tMARedDDBncqvcfCfPIBw=s64","userId":"02797545812686497806"}},"colab":{"base_uri":"https://localhost:8080/","height":176}},"source":["! pip install boto3"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (1.13.3)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3) (0.3.3)\n","Requirement already satisfied: botocore<1.17.0,>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from boto3) (1.16.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3) (0.9.5)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3) (2.8.1)\n","Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3) (1.24.3)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3) (0.15.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.0,>=1.16.3->boto3) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MGahh4OfQ7pA","colab_type":"text"},"source":["## Configuration\n","\n","To use Boto3, you need to set up authentication credentials. Credentials for your AWS account can be found in the IAM Console.\n","\n","Go through the following steps to create a AWS user and generate a new set of keys."]},{"cell_type":"markdown","metadata":{"id":"CCF09N8EY7fF","colab_type":"text"},"source":["1. To create a new AWS user, go to your [AWS Console](https://console.aws.amazon.com/).\n","\n","2. In the top navigation bar, click **Services** and then under **Security, Identity, and Compliance**, click **IAM**.\n","\n","3. Then, from the left navigation, click **Users** > **Add user**.\n","\n","4. Give the user a name (for example, *boto3user*).\n","\n","5. Enable **Programmatic access** to be able to work with the AWS SDK.\n","\n","6. Click **Next:Permissions**.\n","\n","7. For permissions, select **Attach existing policies directly** and choose the **AmazonS3FullAccess** policy.\n","\n","8. Click **Next:Tags**.\n","\n","9. Click **Next:Review**.\n","\n","10. Confirm the user details and click **Create user**.\n","\n","11. Click **Download.csv** to make a copy of your credentials. You will need these later.\n","\n","12. Install the AWS CLI from here: <https://aws.amazon.com/cli/>.\n","\n","13. Run the following command from a terminal window (for example, Git Bash): ```aws configure```\n","\n","  Note: You might need to restart the terminal after installing the AWS CLI.\n","\n","14. When prompted, enter your AWS Access Key ID, which can be found in the csv file you downloaded in step 11.\n","\n","15. When prompted, enter your AWS Secret Access Key, which can be found in the csv file you downloaded in step 11.\n","\n","16. When prompted for a default region name, press Enter to use the default region (us-east-1).\n","\n","17. When prompted for a default output format, press Enter to use the default of None.\n","\n","This sets up credentials for the default profile as well as a default region to use when creating connections."]},{"cell_type":"markdown","metadata":{"id":"GBtLhIMSVT7K","colab_type":"text"},"source":["## Set up S3 Resource\n","\n","Run the following cell to import Boto3 and tell it to use the S3 service.\n","\n","You will also be prompted for your AWS Access Key ID and your AWS Secret Access Key. Both of these can be found in the csv file that you downloaded when you created a AWS user in the previous section."]},{"cell_type":"code","metadata":{"id":"bwYtJvHnZUxJ","colab_type":"code","outputId":"c7438666-e530-4782-9543-a046ad4fac5a","executionInfo":{"status":"ok","timestamp":1589114568364,"user_tz":300,"elapsed":21110,"user":{"displayName":"Philip Stubbs","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs77NEPtyu7xu6gp5w4tMARedDDBncqvcfCfPIBw=s64","userId":"02797545812686497806"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import boto3\n","\n","ACCESS_ID = input('AWS Access Key ID: ')\n","ACCESS_KEY = input('AWS Secret Access Key: ')\n","\n","# Use Amazon S3\n","s3 = boto3.resource('s3', aws_access_key_id=ACCESS_ID, aws_secret_access_key= ACCESS_KEY)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["AWS Access Key ID: AKIASINUSCIKVM6NPRLR\n","AWS Secret Access Key: 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\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S7b9c_XwWK_a","colab_type":"text"},"source":["## Create a S3 Bucket\n","\n","The name of a S3 bucket must be unique across all regions of the AWS platform. The uuid package is used to help ensure that the bucket name is unique by generating a random string of characters at the end of the bucket name you choose."]},{"cell_type":"code","metadata":{"id":"Bs9-X8budhDX","colab_type":"code","colab":{}},"source":["import uuid\n","def create_bucket_name(bucket_prefix):\n","    # The generated bucket name must be between 3 and 63 chars long\n","    return ''.join([bucket_prefix, str(uuid.uuid4())])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5LiS1pmNd1HL","colab_type":"code","colab":{}},"source":["def create_bucket(bucket_prefix, s3_connection):\n","  bucket_name = create_bucket_name(bucket_prefix)\n","  bucket_response = s3_connection.create_bucket(\n","    Bucket=bucket_name)\n","  print(bucket_name)\n","  return bucket_name, bucket_response"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WH5WSA0oeUu5","colab_type":"code","outputId":"c29d11e1-7b99-42df-ddc4-cc7a0ff6d14d","executionInfo":{"status":"ok","timestamp":1589117756546,"user_tz":300,"elapsed":746,"user":{"displayName":"Philip Stubbs","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs77NEPtyu7xu6gp5w4tMARedDDBncqvcfCfPIBw=s64","userId":"02797545812686497806"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["# Create bucket.\n","bucket_name, response = create_bucket('mentalhealthml', s3)\n","\n","print(bucket_name)\n","print(response)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["mentalhealthml24fc4443-f38a-474b-af39-069ee7fd1932\n","mentalhealthml24fc4443-f38a-474b-af39-069ee7fd1932\n","s3.Bucket(name='mentalhealthml24fc4443-f38a-474b-af39-069ee7fd1932')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4k1iV-7fw_Ar","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"6aa29e56-e255-485c-c931-99fadd330dbd","executionInfo":{"status":"ok","timestamp":1589117883654,"user_tz":300,"elapsed":461,"user":{"displayName":"Philip Stubbs","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs77NEPtyu7xu6gp5w4tMARedDDBncqvcfCfPIBw=s64","userId":"02797545812686497806"}}},"source":["# Grant public read access to the bucket that was just created.\n","bucket = s3.Bucket(bucket_name)\n","bucket.Acl().put(ACL='public-read')"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'ResponseMetadata': {'HTTPHeaders': {'content-length': '0',\n","   'date': 'Sun, 10 May 2020 13:38:03 GMT',\n","   'server': 'AmazonS3',\n","   'x-amz-id-2': 'Q1iAFtTYgtfg6t9Y092wnhZaKMTeQeVCGewmU26yya2HlaDY55UMlz3HPEUclIUCNBvj9HsTeP0=',\n","   'x-amz-request-id': 'FAD5B5A54EEFE6EB'},\n","  'HTTPStatusCode': 200,\n","  'HostId': 'Q1iAFtTYgtfg6t9Y092wnhZaKMTeQeVCGewmU26yya2HlaDY55UMlz3HPEUclIUCNBvj9HsTeP0=',\n","  'RequestId': 'FAD5B5A54EEFE6EB',\n","  'RetryAttempts': 0}}"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"kSAJ0CaJ5XVt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":364},"outputId":"ff5f8bdd-7610-40dd-991f-4faaa3220399","executionInfo":{"status":"ok","timestamp":1589119397603,"user_tz":300,"elapsed":313,"user":{"displayName":"Philip Stubbs","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs77NEPtyu7xu6gp5w4tMARedDDBncqvcfCfPIBw=s64","userId":"02797545812686497806"}}},"source":["# Verify that bucket was created.\n","# Print out bucket names.\n","for bucket in s3.buckets.all():\n","    print(bucket.name)"],"execution_count":51,"outputs":[{"output_type":"stream","text":["amplifyexample-20181111091510-deployment\n","artowl.co\n","client-deployments-mobilehub-1930970617\n","client-deployments-mobilehub-237277109\n","client-hosting-mobilehub-1930970617\n","client-hosting-mobilehub-237277109\n","grudges-deployments-mobilehub-1653245828\n","grudges-deployments-mobilehub-661855754\n","grudges-hosting-mobilehub-1653245828\n","grudges-hosting-mobilehub-661855754\n","grudgesappsync-deployments-mobilehub-891706388\n","grudgesappsync-hosting-mobilehub-891706388\n","mentalhealthml24fc4443-f38a-474b-af39-069ee7fd1932\n","phil-data-bootcamp\n","photoalbums-20181117161541-deployment\n","photoalbums71cecdc2603a42998e406bac6622dda7\n","trapperkeepermaster-deployments-mobilehub-1512747905\n","trapperkeepermaster-hosting-mobilehub-1512747905\n","trapperkeepermaster-userfiles-mobilehub-1512747905\n","www.artowl.co\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3Ex-xWcpW-3-","colab_type":"text"},"source":["## Upload the csv data files to the S3 Bucket\n","\n","Run the following cells to upload the csv data files to the S3 bucket you just created."]},{"cell_type":"code","metadata":{"id":"W7a26jL3hpdQ","colab_type":"code","colab":{}},"source":["import glob\n","bucket = s3.Bucket(bucket_name)\n","\n","path_to_csvs = os.path.join(\".\", \"Resources\")\n","all_files = glob.glob(os.path.join(path_to_csvs, \"*.csv\"))\n","for f in all_files:\n","  filename = os.path.basename(f)\n","  # Use method of creating object instance to upload files from local machine to\n","  # S3 bucket using boto3.\n","  s3.Object(bucket_name, filename).upload_file(f)\n","  # Update access controls to allow public reads.\n","  data_file_object = s3.Object(bucket_name, filename)\n","  data_file_object.put(ACL='public-read')"],"execution_count":0,"outputs":[]}]}