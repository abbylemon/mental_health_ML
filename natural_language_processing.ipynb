{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"natural_language_processing.ipynb","provenance":[],"collapsed_sections":["eT_ViV6G0p5M","QVqqYsKo01ia","uaaTfWIj08qa","J1deKtallPx6","P6FDVvgklZAw","IZnUoZL21JEl","ANvEFd4I1V9Z","_7dibdonmE8r","Pd3ky8RWl3XP","EkKjYDQu2sU8","yvZThtG_tnNM","3KTfhpJ1fg1i"],"authorship_tag":"ABX9TyMCocS/8vXghcBhjehvJuzb"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eLniGSBolEuC","colab_type":"text"},"source":["# Natural Language Processing and Sentiment Analysis"]},{"cell_type":"markdown","metadata":{"id":"eT_ViV6G0p5M","colab_type":"text"},"source":["## Set up and Start Spark session"]},{"cell_type":"code","metadata":{"id":"LeFF9aaHmnJb","colab_type":"code","colab":{}},"source":["# Install Java, Spark, and Findspark\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCHZ8n96nRdY","colab_type":"code","colab":{}},"source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"MentalHealthNLP\").getOrCreate()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QVqqYsKo01ia","colab_type":"text"},"source":["## Mount Google Drive into this runtime"]},{"cell_type":"code","metadata":{"id":"bPKgYb0UnWNa","colab_type":"code","colab":{}},"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6diWNjKLneym","colab_type":"code","colab":{}},"source":["%cd /content/gdrive/My Drive/data_final_project/mental_health_ML"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uaaTfWIj08qa","colab_type":"text"},"source":["## Query and load data from Postgres database"]},{"cell_type":"markdown","metadata":{"id":"J1deKtallPx6","colab_type":"text"},"source":["### Install and import dependencies"]},{"cell_type":"code","metadata":{"id":"zh1_W4IQnnaZ","colab_type":"code","colab":{}},"source":["! pip install sqlalchemy\n","\n","import sqlalchemy\n","from sqlalchemy.ext.automap import automap_base\n","from sqlalchemy.orm import Session\n","from sqlalchemy import create_engine, func"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P6FDVvgklZAw","colab_type":"text"},"source":["### Connect to database"]},{"cell_type":"code","metadata":{"id":"_l5JF4FfoAgG","colab_type":"code","colab":{}},"source":["# Database credentials\n","from config import DB_USERNAME, DB_PASSWORD, DB_ENDPOINT\n","\n","# Connect to database.\n","! pip install psycopg2-binary\n","\n","rds_connection_string = f\"{DB_USERNAME}:{DB_PASSWORD}@{DB_ENDPOINT}:5432/mental_health_tech_db\"\n","engine = create_engine(f'postgresql://{rds_connection_string}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fz9xAndnoNRv","colab_type":"code","colab":{}},"source":["# Reflect an existing database into a new model.\n","Base = automap_base()\n","# Reflect the tables.\n","Base.prepare(engine, reflect=True)\n","\n","# Save reference to the tables.\n","Survey = Base.classes.survey_responses\n","print(Base.classes.keys())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWueSXlFoplo","colab_type":"code","colab":{}},"source":["session = Session(engine)\n","\n","surveys = session.query(\n","    Survey.id,\n","    Survey.conversation_with_employer,\n","  ).all()\n","\n","session.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IZnUoZL21JEl","colab_type":"text"},"source":["### Filter out null values (where survey question was unanswered)"]},{"cell_type":"code","metadata":{"id":"kM2laEcfo2Bo","colab_type":"code","colab":{}},"source":["ids = []\n","conversations = []\n","\n","for survey in surveys:\n","  if survey[1] != None:\n","    ids.append(survey[0])\n","    conversations.append(survey[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z21cdrg6ssrP","colab_type":"code","colab":{}},"source":["len(conversations)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ANvEFd4I1V9Z","colab_type":"text"},"source":["## Sentiment Analysis Using VADER and TextBlob\n","\n","Sentiment Analysis tries to identify and extract opinions within a given text. The goal of sentiment analysis is to gauge the attitude, sentiments, evaluations, attitudes and emotions of a speaker/writer based on the computational treatment of subjectivity in a text.\n","\n","For more information, see <https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f>"]},{"cell_type":"markdown","metadata":{"id":"_7dibdonmE8r","colab_type":"text"},"source":["### Calculate sentiment scores"]},{"cell_type":"code","metadata":{"id":"lJhIKudNr7_O","colab_type":"code","colab":{}},"source":["! pip install vaderSentiment\n","! pip install textblob\n","\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","analyser = SentimentIntensityAnalyzer()\n","from textblob import TextBlob"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ruYl_bZ-tF0C","colab_type":"code","colab":{}},"source":["def sentiment_analyzer_scores(sentence):\n","    score = analyser.polarity_scores(sentence)\n","    return score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vLESDlqAtJK8","colab_type":"code","colab":{}},"source":["example_score = sentiment_analyzer_scores(\"The phone is super cool.\")\n","example_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dFxuPFXkxusV","colab_type":"code","colab":{}},"source":["positive_scores = []\n","negative_scores = []\n","neutral_scores = []\n","compound_scores = []\n","textblob_scores = []\n","conversation_classes_vader = []\n","conversation_classes_textblob = []\n","\n","for conversation in conversations:\n","  positive_score = sentiment_analyzer_scores(conversation)[\"pos\"]\n","  negative_score = sentiment_analyzer_scores(conversation)[\"neg\"]\n","  neutral_score = sentiment_analyzer_scores(conversation)[\"neu\"]\n","  compound_score = sentiment_analyzer_scores(conversation)[\"compound\"]\n","  blob = TextBlob(conversation)\n","  textblob_score = blob.sentiment[0]\n","\n","  positive_scores.append(positive_score)\n","  negative_scores.append(negative_score)\n","  neutral_scores.append(neutral_score)\n","  compound_scores.append(compound_score)\n","  textblob_scores.append(textblob_score)\n","\n","  if compound_score >= 0.05:\n","    conversation_class_vader = 'positive'\n","\n","  if compound_score <= -0.05:\n","    conversation_class_vader = 'negative'\n","  \n","  if compound_score < 0.05 and compound_score > -0.05:\n","    conversation_class_vader = 'neutral'\n","\n","  if textblob_score < 0:\n","    conversation_class_textblob = 'negative'\n","\n","  if textblob_score == 0:\n","    conversation_class_textblob = 'neutral'\n","\n","  if textblob_score > 0:\n","    conversation_class_textblob = 'positive'\n","\n","  conversation_classes_vader.append(conversation_class_vader)\n","  conversation_classes_textblob.append(conversation_class_textblob)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KsyWa59krwyS","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","conversations_df = pd.DataFrame({\n","    \"id\": ids,\n","    \"conversation\": conversations,\n","    \"positive_score\": positive_scores,\n","    \"negative_score\": negative_scores,\n","    \"neutral_score\": neutral_scores,\n","    \"compound_score\": compound_scores,\n","    \"textblob_score\": textblob_scores,\n","    \"conversation_class_vader\": conversation_classes_vader,\n","    \"conversation_class_textblob\": conversation_classes_textblob\n","})\n","\n","conversations_df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k_qnzkYhifNk","colab_type":"code","colab":{}},"source":["conversations_df[\"conversation_class_vader\"].value_counts()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kkQBJBciPd55","colab_type":"text"},"source":["The positive, negative, and neutral scores represent the proportion of text that falls in these categories.  All these should add up to 1.\n","\n","The compound score is a metric that calculates the sum of all the ratings which have been normalized between -1(most extreme negative) and +1 (most extreme positive).\n","\n","positive sentiment: compound score >= 0.05<br>\n","neutral sentment: compound score > -0.05 and compound_score < 0.05<br>\n","negative sentiment: compound score <= -0.05"]},{"cell_type":"code","metadata":{"id":"GF1zwDCqk9mK","colab_type":"code","colab":{}},"source":["conversations_df[\"conversation_class_textblob\"].value_counts()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"stXHD4nJdzge","colab_type":"code","colab":{}},"source":["conversations_spark_df = spark.createDataFrame(conversations_df)\n","\n","conversations_spark_df.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pd3ky8RWl3XP","colab_type":"text"},"source":["### Feature Transformations"]},{"cell_type":"code","metadata":{"id":"8zEIwgsud_aM","colab_type":"code","colab":{}},"source":["from pyspark.sql.functions import length\n","# Create a length column to be used as a future feature\n","data_df = conversations_spark_df.withColumn('length', length(conversations_spark_df['conversation']))\n","data_df.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zRsLt9-oeRk0","colab_type":"code","colab":{}},"source":["from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n","# Create all the features to the data set\n","pos_neg_to_num_vader = StringIndexer(inputCol='conversation_class_vader',outputCol='label_vader')\n","pos_neg_to_num_textblob = StringIndexer(inputCol='conversation_class_textblob',outputCol='label_textblob')\n","\n","tokenizer = Tokenizer(inputCol=\"conversation\", outputCol=\"token_text\")\n","\n","stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n","\n","hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n","\n","idf = IDF(inputCol='hash_token', outputCol='idf_token')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hVBtr6bEefRd","colab_type":"code","colab":{}},"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.linalg import Vector\n","\n","# Create feature vectors\n","clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jruQLTqPek4R","colab_type":"code","colab":{}},"source":["# Create a and run a data processing Pipeline\n","from pyspark.ml import Pipeline\n","data_prep_pipeline_vader = Pipeline(stages=[pos_neg_to_num_vader, tokenizer, stopremove, hashingTF, idf, clean_up])\n","data_prep_pipeline_textblob = Pipeline(stages=[pos_neg_to_num_textblob, tokenizer, stopremove, hashingTF, idf, clean_up])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5RgSVPu5eoef","colab_type":"code","colab":{}},"source":["# Fit and transform the pipeline\n","cleaner_vader = data_prep_pipeline_vader.fit(data_df)\n","cleaned_vader = cleaner_vader.transform(data_df)\n","\n","cleaner_textblob = data_prep_pipeline_textblob.fit(data_df)\n","cleaned_textblob = cleaner_textblob.transform(data_df)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"68HWXsTEexAG","colab_type":"code","colab":{}},"source":["# Show label and resulting features\n","cleaned_vader = cleaned_vader.withColumnRenamed(\"label_vader\",\"label\")\n","cleaned_vader.select(['label', 'features']).show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aD2PuFropRJM","colab_type":"code","colab":{}},"source":["# Show label and resulting features\n","cleaned_textblob = cleaned_textblob.withColumnRenamed(\"label_textblob\",\"label\")\n","cleaned_textblob.select(['label', 'features']).show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iUQphXfKexHA","colab_type":"code","colab":{}},"source":["from pyspark.ml.classification import NaiveBayes\n","# Break data down into a training set and a testing set\n","training_vader, testing_vader = cleaned_vader.randomSplit([0.9, 0.1])\n","training_textblob, testing_textblob = cleaned_textblob.randomSplit([0.9, 0.1])\n","\n","# Create a Naive Bayes model and fit training data\n","nb = NaiveBayes()\n","predictor_vader = nb.fit(training_vader)\n","predictor_textblob = nb.fit(training_textblob)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F0SyCo2Pe9m5","colab_type":"code","colab":{}},"source":["# Tranform the model with the testing data\n","test_results_vader = predictor_vader.transform(testing_vader)\n","test_results_vader.show(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Oa-IEvhq4wj","colab_type":"code","colab":{}},"source":["# Tranform the model with the testing data\n","test_results_textblob = predictor_textblob.transform(testing_textblob)\n","test_results_textblob.show(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lCsgvRbGfJac","colab_type":"code","colab":{}},"source":["# Use the Class Evaluator for a cleaner description\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","\n","acc_eval = MulticlassClassificationEvaluator()\n","acc_vader = acc_eval.evaluate(test_results_vader)\n","acc_textblob = acc_eval.evaluate(test_results_textblob)\n","print(\"Accuracy of model at predicting sentiment of conversation with VADER was: %f\" % acc_vader)\n","print(\"Accuracy of model at predicting sentiment of conversation with textblob was: %f\" % acc_textblob)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EkKjYDQu2sU8","colab_type":"text"},"source":["## Word Cloud"]},{"cell_type":"code","metadata":{"id":"7E1DNOUG2tqh","colab_type":"code","colab":{}},"source":["! pip install wordcloud"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4N8MIWE62wI7","colab_type":"code","colab":{}},"source":["from wordcloud import WordCloud, STOPWORDS\n","import matplotlib.pyplot as plt\n","% matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-5yD8f7r23pr","colab_type":"code","colab":{}},"source":["text = \" \".join(conversation for conversation in conversations)\n","print (\"There are {} words in the combination of all conversations\".format(len(text)))\n","\n","stopwords = set(STOPWORDS)\n","stopwords.update([\"thing\", \"spoke\", \"day\", \"week\", \"make\", \"much\", \"something\", \"taking\", \"made\", \"go\", \"took\", \"take\", \"let\", \"going\", \"never\", \"things\", \"taken\", \"way\", \"manager\"])\n","\n","# Create and generate a word cloud image:\n","wordcloud = WordCloud(stopwords=stopwords, max_words=300, background_color=\"#333\", width=3000, height=1000).generate(text)\n","\n","# Display the generated image:\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis(\"off\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AespTaA04BTu","colab_type":"code","colab":{}},"source":["# Save the image in the shared google drive folder:\n","wordcloud.to_file(\"/content/gdrive/My Drive/shared_data_final_project/conversations_word_cloud.png\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yvZThtG_tnNM","colab_type":"text"},"source":["## Naive Bayes Classifier"]},{"cell_type":"code","metadata":{"id":"tK6M1_I7tt5x","colab_type":"code","colab":{}},"source":["from textblob.classifiers import NaiveBayesClassifier, DecisionTreeClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yqWKtMAltxiq","colab_type":"code","colab":{}},"source":["conversations_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MvcD6htMt0r3","colab_type":"code","colab":{}},"source":["naive_bayes_classifier_df = conversations_df[[\"conversation\", \"conversation_class_textblob\"]]\n","\n","naive_bayes_classifier_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MS7Rh_0wuEwG","colab_type":"code","colab":{}},"source":["naive_bayes_classifier_df = naive_bayes_classifier_df[naive_bayes_classifier_df['conversation_class_textblob'] != \"neutral\"]\n","\n","naive_bayes_classifier_df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NqLnfTCFu_7I","colab_type":"code","colab":{}},"source":["naive_bayes_classifier_df[\"conversation_class_textblob\"] = naive_bayes_classifier_df[\"conversation_class_textblob\"].replace({\n","    \"positive\": \"pos\",\n","    \"negative\": \"neg\"\n","})\n","\n","naive_bayes_classifier_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mcf1xZpguyqn","colab_type":"code","colab":{}},"source":["tuples = [tuple(x) for x in naive_bayes_classifier_df.to_numpy()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTnYkbNJwmqU","colab_type":"code","colab":{}},"source":["len(tuples)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SC-JQceiw2Zf","colab_type":"code","colab":{}},"source":["# Create training and testing data.\n","import random\n","random.shuffle(tuples)\n","\n","length = len(tuples)\n","middle_index = length//2\n","\n","train = tuples[:middle_index]\n","test = tuples[middle_index:]\n","\n","len(train)\n","len(test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2HQHHBFkyLB0","colab_type":"code","colab":{}},"source":["! pip install -U textblob nltk\n","! python -m textblob.download_corpora"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o3hZUoiOx5z5","colab_type":"code","colab":{}},"source":["cl = NaiveBayesClassifier(train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mg1GDSJ1ve4g","colab_type":"code","colab":{}},"source":["cl.classify(\"I talked to my manager about mental health he was very supportive.\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d-B9TpL6yfJ6","colab_type":"code","colab":{}},"source":["cl.accuracy(test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KW8J_8M9yrt6","colab_type":"code","colab":{}},"source":["cl.show_informative_features(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZLoqTapfWia","colab_type":"code","colab":{}},"source":["import joblib\n","joblib.dump(cl, '/content/gdrive/My Drive/shared_data_final_project/nb_classifier2.pkl', compress=9)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3KTfhpJ1fg1i","colab_type":"text"},"source":["## Decision Tree Classifier"]},{"cell_type":"code","metadata":{"id":"w9Ucyn8iRSu9","colab_type":"code","colab":{}},"source":["# Decision tree classifier\n","dt_classifier = DecisionTreeClassifier(train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xm5qeIW-SzHE","colab_type":"code","colab":{}},"source":["# Now, letâ€™s check the accuracy of this classifier on the testing dataset.\n","dt_classifier.accuracy(test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pPldAb8fZp0D","colab_type":"code","colab":{}},"source":["dt_classifier.classify('I talked to my manager about mental health he was very supportive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zcY4UlyIc2Ee","colab_type":"code","colab":{}},"source":["import joblib\n","joblib.dump(cl, '/content/gdrive/My Drive/shared_data_final_project/dt_classifier.pkl', compress=9)"],"execution_count":0,"outputs":[]}]}