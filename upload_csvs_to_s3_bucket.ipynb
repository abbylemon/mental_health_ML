{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"upload_csvs_to_s3_bucket.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO9kaFxsQjdFRWAUXypntH2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"R9A_8j0EoEBJ","colab_type":"text"},"source":["# Create S3 Bucket and Upload CSV files to S3\n","\n","Run through the following cells to create a S3 bucket and upload the csv data files for this project to S3.\n","\n","Make sure to go to the **Edit** menu and click **Clear all outputs** before and after running this notebook."]},{"cell_type":"markdown","metadata":{"id":"R7HKSTcioMEp","colab_type":"text"},"source":["## Set up Spark Session"]},{"cell_type":"code","metadata":{"id":"fDzMYzwNnoaM","colab_type":"code","colab":{}},"source":["# Install Java, Spark, and Findspark\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s54HLFBXoHxg","colab_type":"code","colab":{}},"source":["!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SWtPDJwooTwX","colab_type":"code","colab":{}},"source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"S3Setup\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BYKFqNt2ovYW","colab_type":"text"},"source":["## Mount Google Drive into this runtime\n","\n","To upload the csv data files to a S3 bucket, you need to mount your google drive into this runtime. To do that, run the following cells.\n","\n","This will prompt a URL with an authentication code. After you go to the URL and insert that authentication code in the provided space, your google drive will be mounted."]},{"cell_type":"code","metadata":{"id":"bVR855UyoylR","colab_type":"code","colab":{}},"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uMg-dMUbo1po","colab_type":"code","colab":{}},"source":["# Check the contents of the current folder in the runtime.\n","! ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RHp-efM1o501","colab_type":"code","colab":{}},"source":["# If the drive is mounted correcly, you will see that the current folder has a directory called gdrive.\n","# This is where you can find your google drive contents. \n","%cd /content/gdrive/My Drive"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"trMxuu0FpCWc","colab_type":"text"},"source":["## Extract the csv data files from the zip file\n","\n","Running this cell will extract the csv data files from the .zip file inside the Resources folder of the repository."]},{"cell_type":"code","metadata":{"id":"LtXS-RDMpX1R","colab_type":"code","colab":{}},"source":["%cd /content/gdrive/My Drive/data_final_project/mental_health_ML"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KtQkBE6npDMn","colab_type":"code","colab":{}},"source":["import zipfile\n","\n","# unzip files in Resources folder.\n","extension = \".zip\"\n","extracted_dir_name = \".\"\n","\n","# Get the current working directory.\n","# Need to be in root directory of repo for this to work.\n","cwd_dir_name = os.getcwd()\n","print(f\"The current working directory is {cwd_dir_name}.\")\n","\n","# change directory from working dir to dir with zip file.\n","os.chdir(\"Resources\")\n","# This should be the \"Resources\" folder.\n","dir_name = os.getcwd()\n","print(f\"You are now in the following directory: {dir_name}.\")\n","\n","# loop through the items in the directory.\n","for item in os.listdir(dir_name):\n","  # check for \".zip\" extension\"\n","  if item.endswith(extension):\n","    try:\n","      # get full path of files\n","      file_name = os.path.abspath(item)\n","      # create zipfile object\n","      zip_ref = zipfile.ZipFile(file_name)\n","      # reference to the directory where the zip files will be extracted.\n","      unzipped_directory = os.path.join(extracted_dir_name)\n","      # extract file to dir\n","      zip_ref.extractall(unzipped_directory)\n","      # close file\n","      zip_ref.close()\n","      print(f\"Successfully unzipped {item} into the following folder:{dir_name}.\")\n","    except Exception as e:\n","      print(f\"Error trying to unzip data file(s).\")\n","      print(e)\n","            \n","# Go up one directory into the repo root directory.\n","os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir))\n","print(os.path.normpath(os.getcwd() + os.sep + os.pardir))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sLUIYLdcpm7C","colab_type":"text"},"source":["## Install Boto3\n","\n","Boto3 is the AWS SDK for Python to create, configure, and manage AWS Services, such as S3."]},{"cell_type":"code","metadata":{"id":"CkuoZpI-pnUC","colab_type":"code","colab":{}},"source":["! pip install boto3"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Hq3FSj4pqil","colab_type":"text"},"source":["## Configuration\n","\n","To use Boto3, you need to set up authentication credentials. Credentials for your AWS account can be found in the IAM Console.\n","\n","Go through the following steps to create a AWS user and generate a new set of keys."]},{"cell_type":"markdown","metadata":{"id":"VrVqK4HYpyE6","colab_type":"text"},"source":["1. To create a new AWS user, go to your [AWS Console](https://console.aws.amazon.com/).\n","\n","2. In the top navigation bar, click **Services** and then under **Security, Identity, and Compliance**, click **IAM**.\n","\n","3. Then, from the left navigation, click **Users** > **Add user**.\n","\n","4. Give the user a name (for example, *boto3user*).\n","\n","5. Enable **Programmatic access** to be able to work with the AWS SDK.\n","\n","6. Click **Next:Permissions**.\n","\n","7. For permissions, select **Attach existing policies directly** and choose the **AmazonS3FullAccess** policy.\n","\n","8. Click **Next:Tags**.\n","\n","9. Click **Next:Review**.\n","\n","10. Confirm the user details and click **Create user**.\n","\n","11. Click **Download.csv** to make a copy of your credentials. You will need these later.\n","\n","12. Install the AWS CLI from here: <https://aws.amazon.com/cli/>.\n","\n","13. Run the following command from a terminal window (for example, Git Bash): ```aws configure```\n","\n","  Note: You might need to restart the terminal after installing the AWS CLI.\n","\n","14. When prompted, enter your AWS Access Key ID, which can be found in the csv file you downloaded in step 11.\n","\n","15. When prompted, enter your AWS Secret Access Key, which can be found in the csv file you downloaded in step 11.\n","\n","16. When prompted for a default region name, press Enter to use the default region (us-east-1).\n","\n","17. When prompted for a default output format, press Enter to use the default of None.\n","\n","This sets up credentials for the default profile as well as a default region to use when creating connections."]},{"cell_type":"markdown","metadata":{"id":"lQp3Icxmp4Dy","colab_type":"text"},"source":["## Set up S3 Resource\n","\n","Run the following cell to import Boto3 and tell it to use the S3 service.\n","\n","You will also need to import the AWS access key id and access key secret from the config.py file."]},{"cell_type":"code","metadata":{"id":"Or8R44iJp4cb","colab_type":"code","colab":{}},"source":["import boto3\n","from config import ACCESS_ID, ACCESS_KEY\n","\n","# Use Amazon S3\n","s3 = boto3.resource('s3', aws_access_key_id=ACCESS_ID, aws_secret_access_key= ACCESS_KEY)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MrSXhPS4qVMa","colab_type":"text"},"source":["## Create a S3 Bucket\n","\n","The name of a S3 bucket must be unique across all regions of AWS. The uuid package is used to help ensure that the bucket name is unique by generating a random string of characters at the end of the bucket name you choose."]},{"cell_type":"code","metadata":{"id":"fBKjcduUqV69","colab_type":"code","colab":{}},"source":["import uuid\n","def create_bucket_name(bucket_prefix):\n","    # The generated bucket name must be between 3 and 63 chars long\n","    return ''.join([bucket_prefix, str(uuid.uuid4())])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GVubPMqNqXqg","colab_type":"code","colab":{}},"source":["def create_bucket(bucket_prefix, s3_connection):\n","  bucket_name = create_bucket_name(bucket_prefix)\n","  bucket_response = s3_connection.create_bucket(\n","    Bucket=bucket_name)\n","  print(bucket_name)\n","  return bucket_name, bucket_response"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g9imk36yqZKb","colab_type":"code","colab":{}},"source":["# Create bucket.\n","bucket_name, response = create_bucket('mentalhealthml', s3)\n","\n","print(bucket_name)\n","print(response)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DqLJU9qdqcGc","colab_type":"code","colab":{}},"source":["# Grant public read access to the bucket that was just created.\n","bucket = s3.Bucket(bucket_name)\n","bucket.Acl().put(ACL='public-read')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wF46W3Yrqd84","colab_type":"code","colab":{}},"source":["# Verify that bucket was created.\n","# Print out bucket names.\n","for bucket in s3.buckets.all():\n","    print(bucket.name)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6RnV_4oqiIl","colab_type":"text"},"source":["## Upload the csv data files to the S3 Bucket\n","\n","Run the following cells to upload the csv data files to the S3 bucket you just created."]},{"cell_type":"code","metadata":{"id":"k2r0Lg-LqifL","colab_type":"code","colab":{}},"source":["# import glob\n","# bucket = s3.Bucket(bucket_name)\n","\n","# path_to_csvs = os.path.join(\".\", \"Resources\")\n","# all_files = glob.glob(os.path.join(path_to_csvs, \"*.csv\"))\n","# for f in all_files:\n","#   filename = os.path.basename(f)\n","#   # Use method of creating object instance to upload files from local machine to\n","#   # S3 bucket using boto3.\n","#   # s3.Object(bucket_name, filename).upload_file(f)\n","#   # s3.Object(bucket_name, filename).put(Body=open(f, 'rb'))\n","#   s3.Bucket(bucket_name).upload_file(\n","#     Filename=f, Key=file_name)\n","#   # Update access controls to allow public reads.\n","#   data_file_object = s3.Object(bucket_name, filename)\n","#   data_file_object.put(ACL='public-read')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ddF0MWxxqmp6","colab_type":"code","colab":{}},"source":["# Verify that files/objects were succesfully uploaded to S3.\n","# for my_bucket_object in bucket.objects.all():\n","#     print(my_bucket_object)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fpBZdsX4qqae","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}